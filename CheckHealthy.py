from ew_config.source import *
from ew_api.curl_infra import CurlInfra
from ew_api.openai_infra import OpenaiInfra
from api_key_manager.client import APIKeyManagerClient
from ew_config.logging_config import setup_optimized_logging, create_error_summary
from tqdm import tqdm
from fastapi import FastAPI, BackgroundTasks, HTTPException
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from datetime import datetime
from collections import deque, defaultdict
import uvicorn
import os
import json
import logging
import uuid
import base64

# ä½¿ç”¨ä¼˜åŒ–çš„æ—¥å¿—é…ç½®
logger = setup_optimized_logging(
    log_level=logging.INFO,
    console_format='simple',     # æ§åˆ¶å°ä½¿ç”¨ç®€æ´æ ¼å¼
    file_format='structured',    # æ–‡ä»¶ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼
    enable_file_logging=True,
    log_file='health_check.log'
)

app = FastAPI(title="API Health Check Service")

health_data = {}

# æœ€å¤§å‚¨å­˜å¤šå°‘æ¬¡æ£€æŸ¥çš„å†å², å…ˆè¿›å…ˆå‡º, åè¿›æ·»åŠ åœ¨æœ«å°¾. é»˜è®¤å‚¨å­˜100æ¡.
MAX_WINDOW_SIZE = int(os.environ.get("MAX_WINDOW_SIZE", 100))
# å®šæ—¶å™¨è®¾ç½®: æ¯å¤šå°‘åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡çŠ¶æ€. é»˜è®¤15åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡.
CHECK_TIMER_SPAN = int(os.environ.get("CHECK_TIMER_SPAN", 30))
API_KEY_MANAGER_URL = os.environ.get("API_KEY_MANAGER_URL", "http://localhost:8002")
HEALTH_CHECK_TIMEOUT = int(os.environ.get("HEALTH_CHECK_TIMEOUT", 30))
# å¤šæ¨¡æ€æ¨¡å‹ä¸“ç”¨è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤60ç§’
HEALTH_CHECK_TIMEOUT_MM = int(os.environ.get("HEALTH_CHECK_TIMEOUT_MM", 60))

# åŠ è½½æµ‹è¯•å›¾ç‰‡ï¼ˆç”¨äºå¤šæ¨¡æ€æ¨¡å‹æµ‹è¯•ï¼‰
TEST_IMAGE_BASE64 = None
TEST_IMAGE_PATH = os.path.join(os.path.dirname(__file__), "test.jpg")

if os.path.exists(TEST_IMAGE_PATH):
    try:
        with open(TEST_IMAGE_PATH, "rb") as img_file:
            TEST_IMAGE_BASE64 = base64.b64encode(img_file.read()).decode("utf-8")
        logger.info(f"æµ‹è¯•å›¾ç‰‡åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.warning(f"æµ‹è¯•å›¾ç‰‡åŠ è½½å¤±è´¥: {str(e)}")

def _is_commercial_error(error_message):
    """åˆ¤æ–­æ˜¯å¦ä¸ºå•†ä¸šæ€§é”™è¯¯ï¼ˆå¦‚ä½™é¢ä¸è¶³ã€é…é¢è¶…é™ç­‰ï¼‰
    
    Args:
        error_message (str): é”™è¯¯æ¶ˆæ¯
        
    Returns:
        bool: å¦‚æœæ˜¯å•†ä¸šæ€§é”™è¯¯è¿”å›Trueï¼ŒæŠ€æœ¯æ€§é”™è¯¯è¿”å›False
    """
    commercial_error_keywords = [
        "negative balance",
        "insufficient balance", 
        "quota exceeded",
        "insufficient_user_quota",
        "rate limit",
        "billing",
        "payment",
        "credit",
        "funds",
        "pre-payment",
        "subscription"
    ]
    
    error_lower = error_message.lower()
    return any(keyword in error_lower for keyword in commercial_error_keywords)

def _is_timeout_error(error_message):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¶…æ—¶é”™è¯¯
    
    Args:
        error_message (str): é”™è¯¯æ¶ˆæ¯
        
    Returns:
        bool: å¦‚æœæ˜¯è¶…æ—¶é”™è¯¯è¿”å›True
    """
    timeout_keywords = [
        "timeout",
        "timed out",
        "execution timeout",
        "connection timeout",
        "read timeout",
        "request timeout",
        "æ‰§è¡Œè¶…æ—¶",
        "è¿æ¥è¶…æ—¶",
        "è¯·æ±‚è¶…æ—¶",
        "å“åº”è¶…æ—¶"
    ]
    
    error_lower = error_message.lower()
    return any(keyword in error_lower for keyword in timeout_keywords)

def _get_error_level_and_message(error_message, error_type, source_name=None, model_name=None):
    """æ ¹æ®é”™è¯¯ç±»å‹ç¡®å®šæ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯
    
    Args:
        error_message (str): é”™è¯¯æ¶ˆæ¯
        error_type (str): é”™è¯¯ç±»å‹
        source_name (str): æºåç§°
        model_name (str): æ¨¡å‹åç§°
        
    Returns:
        tuple: (log_level, should_log, log_message)
            - log_level: 'ERROR', 'WARNING', 'DEBUG'
            - should_log: bool, æ˜¯å¦åº”è¯¥è®°å½•æ—¥å¿—
            - log_message: str, æ—¥å¿—æ¶ˆæ¯
    """
    # åˆ›å»ºç®€æ´çš„é”™è¯¯æ‘˜è¦
    error_summary = create_error_summary(error_message, error_type, source_name, model_name)
    
    if _is_commercial_error(error_message):
        # å•†ä¸šæ€§é”™è¯¯ï¼šWARNINGçº§åˆ«ï¼Œä¸éœ€è¦è¯¦ç»†å †æ ˆ
        return 'WARNING', True, f"ğŸ’° {error_summary}"
    elif _is_timeout_error(error_message):
        # è¶…æ—¶é”™è¯¯ï¼šWARNINGçº§åˆ«
        return 'WARNING', True, f"â° {error_summary}"
    elif "invalid.*api.*key" in error_message.lower():
        # APIå¯†é’¥é”™è¯¯ï¼šERRORçº§åˆ«
        return 'ERROR', True, f"ğŸ”‘ {error_summary}"
    else:
        # å…¶ä»–æŠ€æœ¯æ€§é”™è¯¯ï¼šERRORçº§åˆ«
        return 'ERROR', True, f"ğŸ› {error_summary}"

def _build_multimodal_message(prompt, test_image_base64, source_name):
    """æ ¹æ®ä¸åŒä¾›åº”å•†æ„å»ºæ­£ç¡®æ ¼å¼çš„å¤šæ¨¡æ€æ¶ˆæ¯
    
    Args:
        prompt (str): æ–‡æœ¬æç¤º
        test_image_base64 (str): Base64ç¼–ç çš„æµ‹è¯•å›¾åƒ
        source_name (str): ä¾›åº”å•†åç§°
        
    Returns:
        tuple: (primary_messages, fallback_messages) ä¸¤ç§æ ¼å¼çš„æ¶ˆæ¯
    """
    # æ„å»ºå›¾åƒURL
    image_data_url = f"data:image/jpeg;base64,{test_image_base64}"
    
    # å¯¹è±¡æ ¼å¼ï¼ˆOpenAIç­‰ä½¿ç”¨ï¼‰
    object_format_messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {"url": image_data_url}
                }
            ]
        }
    ]
    
    # å­—ç¬¦ä¸²æ ¼å¼ï¼ˆDeepInfraç­‰ä½¿ç”¨ï¼‰
    string_format_messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": image_data_url  # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²ï¼Œä¸æ˜¯å¯¹è±¡
                }
            ]
        }
    ]
    
    # æ ¹æ®æµ‹è¯•ç»“æœï¼Œå¤§éƒ¨åˆ†æºéƒ½åå¥½å¯¹è±¡æ ¼å¼
    # åªæœ‰æå°‘æ•°æºå¯èƒ½éœ€è¦å­—ç¬¦ä¸²æ ¼å¼ä½œä¸ºå¤‡ç”¨
    return object_format_messages, string_format_messages

class CheckHealthy:
    """æµ‹è¯•æ‰€æœ‰æºçš„æ‰€æœ‰æ¨¡å‹, è¿”å›ä¸€ä¸ªæ‰§è¡Œæ—¶é—´.
    æ”¹é€ æˆå¼‚æ­¥å®šæ—¶ä»»åŠ¡."""
    
    @staticmethod
    def run():
        data_structure = {}
        logger.info("ğŸ¥ å¼€å§‹å¥åº·æ£€æŸ¥...")
        
        # åˆå§‹åŒ–APIå¯†é’¥ç®¡ç†å™¨å®¢æˆ·ç«¯
        api_key_client = APIKeyManagerClient(API_KEY_MANAGER_URL)
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        total_tests = 0
        success_count = 0
        error_count = 0
        
        try:
            # è·å–æ‰€æœ‰æ¨¡å‹åˆ—è¡¨
            all_models = model_list_normal + model_list_thinking + model_list_mm_normal + model_list_mm_thinking
            
            # ä½¿ç”¨å±‚çº§å±è”½é€»è¾‘è¿‡æ»¤æ¨¡å‹
            models_to_check = [model for model in all_models if not is_model_health_check_blacklisted(model)]
            blacklisted_models = [model for model in all_models if is_model_health_check_blacklisted(model)]
            
            if blacklisted_models:
                # åˆ†æå±è”½åŸå› 
                exact_matches = [model for model in blacklisted_models if model in health_check_blacklist]
                hierarchical_matches = [model for model in blacklisted_models if model not in health_check_blacklist]
                
                logger.info(f"ğŸš« è·³è¿‡å¥åº·æ£€æµ‹çš„å±è”½æ¨¡å‹: {', '.join(blacklisted_models)}")
                if exact_matches:
                    logger.info(f"  - ç²¾ç¡®åŒ¹é…å±è”½: {', '.join(exact_matches)}")
                if hierarchical_matches:
                    logger.info(f"  - å±‚çº§å±è”½(å¤šæ¨¡æ€): {', '.join(hierarchical_matches)}")
            
            logger.info(f"ğŸ¥ è®¡åˆ’æ£€æµ‹ {len(models_to_check)} ä¸ªæ¨¡å‹ï¼Œè·³è¿‡ {len(blacklisted_models)} ä¸ªå±è”½æ¨¡å‹")
            
            # åœ¨è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨ä¸­éå†æ¯ä¸ªè‡ªå®šä¹‰æ¨¡å‹åï¼ˆæ’é™¤å±è”½çš„æ¨¡å‹ï¼‰
            for model_name in tqdm(models_to_check, desc="å¥åº·æ£€æŸ¥"):
                # åœ¨æº-è‡ªå®šä¹‰æ¨¡å‹å-æºæ¨¡å‹åçš„æ˜ å°„è¡¨ä¸­, éå†æ¯ä¸€ä¸ªæº
                for source_name in source_mapping:
                    try:
                        # å¤šæ¨¡æ€æ¨¡å‹å’Œéå¤šæ¨¡æ€æ¨¡å‹ç°åœ¨éƒ½æ˜¯åŒä¸€ä¸ªæ¨¡å‹å, å› æ­¤åœ¨æˆ‘ä»¬è¿™è¾¹, é è‡ªå®šä¹‰æ¨¡å‹ååé¢çš„"_mm"æ¥åŒºåˆ«.
                        # åœ¨æºä¸­, é€šè¿‡è‡ªå®šä¹‰æ¨¡å‹å, æˆ–å¤šæ¨¡æ€å¤§æ¨¡å‹è‡ªå®šä¹‰æ¨¡å‹åå¯¹åº”çš„è‡ªå®šä¹‰æ¨¡å‹å, æ¥å–å›æºæ¨¡å‹å, ä½†æºæ¨¡å‹åæ˜¯å¯èƒ½ä¸å­˜åœ¨çš„.
                        base_model_name = model_name[:-3] if model_name.endswith("_mm") else model_name
                        
                        # æ£€æŸ¥æºæ˜¯å¦æ”¯æŒè¿™ä¸ªæ¨¡å‹
                        if source_name not in source_mapping or base_model_name not in source_mapping[source_name]:
                            continue  # è·³è¿‡ä¸æ”¯æŒçš„æ¨¡å‹
                            
                        source_model_name = source_mapping[source_name][base_model_name]
                        
                        if source_model_name:
                            total_tests += 1
                            
                            start_time = datetime.now()
                            
                            # è·Ÿæ®æµ‹è¯•æºé…ç½®æ–‡ä»¶, è·å–test-api_key.
                            api_key = api_key_client.get_api_key(source_name)
                            if not api_key:
                                logger.warning(f"ğŸ“­ æ— å¯ç”¨APIå¯†é’¥: {source_name}|{model_name}")
                                data_structure[f"{source_name}|{model_name}"] = None
                                error_count += 1
                                continue
                            
                            # ç¡®å®šæ˜¯å¦ä¸ºå¤šæ¨¡æ€æ¨¡å‹å’Œå¯¹åº”çš„è¶…æ—¶æ—¶é—´
                            is_multimodal = model_name.endswith("_mm")
                            timeout = HEALTH_CHECK_TIMEOUT_MM if is_multimodal else HEALTH_CHECK_TIMEOUT
                            
                            # æ„å»ºæ¶ˆæ¯
                            if is_multimodal and TEST_IMAGE_BASE64:
                                prompt = "Describe this image in exactly 5 words"
                                primary_messages, fallback_messages = _build_multimodal_message(prompt, TEST_IMAGE_BASE64, source_name)
                            else:
                                # éå¤šæ¨¡æ€æ¨¡å‹ä½¿ç”¨æ–‡æœ¬æ¶ˆæ¯
                                primary_messages = [{"role": "user", "content": "Hello!"}]
                                fallback_messages = primary_messages
                            
                            # æµ‹è¯•é€šè¿‡openai-api-sdkæ¥è¿æ¥æºçš„æ¨¡å‹.
                            if "openai" in source_config[source_name]:
                                source_config_openai = source_config[source_name]["openai"]
                                openai_infra = OpenaiInfra(source_config_openai, api_key)
                                try:
                                    # å¥åº·æ£€æŸ¥ä½¿ç”¨è¾ƒå°çš„max_tokensä»¥èŠ‚çœæˆæœ¬å’Œæ—¶é—´
                                    health_check_params = {"max_tokens": 100}
                                    
                                    # å…ˆå°è¯•ä¸»è¦æ ¼å¼
                                    try:
                                        openai_result = openai_infra.get_response(primary_messages, [], source_model_name, timeout=timeout, additional_params=health_check_params)
                                    except Exception as primary_error:
                                        # å¦‚æœæ˜¯å¤šæ¨¡æ€ä¸”æ ¼å¼é”™è¯¯ï¼Œå°è¯•å¤‡ç”¨æ ¼å¼
                                        if is_multimodal and "invalid type" in str(primary_error).lower():
                                            openai_result = openai_infra.get_response(fallback_messages, [], source_model_name, timeout=timeout, additional_params=health_check_params)
                                        else:
                                            raise primary_error
                                    
                                    end_time = datetime.now()
                                    if openai_result and "execution_time" in openai_result:
                                        execution_time = openai_result["execution_time"]
                                        data_structure[f"{source_name}|{model_name}"] = execution_time
                                        success_count += 1
                                        logger.debug(f"âœ… {source_name}|{model_name} - {execution_time:.2f}s")
                                    else:
                                        # å¦‚æœæ²¡æœ‰è¿”å›ç»“æœæˆ–ç¼ºå°‘execution_timeï¼Œå¯èƒ½æ˜¯éšæ€§è¶…æ—¶æˆ–APIå“åº”ä¸å®Œæ•´
                                        execution_time = (end_time - start_time).total_seconds()
                                        data_structure[f"{source_name}|{model_name}"] = None
                                        error_count += 1
                                        
                                        # è®°å½•ä¸ºè¶…æ—¶WARNINGçº§åˆ«
                                        logger.warning(f"â° æ— å“åº”: {source_name}|{model_name} ({execution_time:.2f}s)", 
                                                      extra={
                                                          'source': source_name,
                                                          'model': model_name,
                                                          'api_type': 'OpenAI',
                                                          'timeout': timeout,
                                                          'execution_time': execution_time,
                                                          'error_type': 'NoResponse'
                                                      })
                                    request_id = str(uuid.uuid4())
                                    
                                    # è®°å½•APIå¯†é’¥ä½¿ç”¨æƒ…å†µï¼ˆæˆåŠŸï¼‰
                                    api_key_client.notice_api_key_usage(
                                        api_key=api_key,
                                        model_name=source_model_name,
                                        source_name=source_name,
                                        create_time=start_time,
                                        finish_time=end_time,
                                        execution_time=execution_time,
                                        status=True,
                                        prompt_tokens=openai_result.get("prompt_tokens"),
                                        completion_tokens=openai_result.get("completion_tokens"),
                                        request_id=request_id,
                                        remark="æµ‹è¯•-å¥åº·ç›‘æµ‹"
                                    )
                                except Exception as e:
                                    end_time = datetime.now()
                                    execution_time = (end_time - start_time).total_seconds()
                                    request_id = str(uuid.uuid4())
                                    error_count += 1
                                    
                                    # è®°å½•APIå¯†é’¥ä½¿ç”¨æƒ…å†µï¼ˆå¤±è´¥ï¼‰
                                    api_key_client.notice_api_key_usage(
                                        api_key=api_key,
                                        model_name=source_model_name,
                                        source_name=source_name,
                                        create_time=start_time,
                                        finish_time=end_time,
                                        execution_time=execution_time,
                                        status=False,
                                        request_id=request_id,
                                        remark="æµ‹è¯•-å¥åº·ç›‘æµ‹"
                                    )
                                    
                                    # æ ¹æ®é”™è¯¯ç±»å‹ç¡®å®šæ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯
                                    log_level, should_log, log_message = _get_error_level_and_message(
                                        str(e), type(e).__name__, source_name, model_name)
                                    
                                    if should_log:
                                        extra_info = {
                                            'source': source_name,
                                            'model': model_name,
                                            'api_type': 'OpenAI',
                                            'timeout': timeout,
                                            'error_type': type(e).__name__,
                                            'execution_time': execution_time
                                        }
                                        
                                        if log_level == 'ERROR':
                                            logger.error(log_message, extra=extra_info)
                                        elif log_level == 'WARNING':
                                            logger.warning(log_message, extra=extra_info)
                                        else:  # DEBUG
                                            logger.debug(log_message, extra=extra_info)
                                    data_structure[f"{source_name}|{model_name}"] = None
                                    
                            # æµ‹è¯•åŸºäºcurlç›´è¿.
                            elif "curl" in source_config[source_name]:
                                source_config_curl = source_config[source_name]["curl"]
                                curl_infra = CurlInfra(source_config_curl, api_key)
                                try:
                                    # å¥åº·æ£€æŸ¥ä½¿ç”¨è¾ƒå°çš„max_tokensä»¥èŠ‚çœæˆæœ¬å’Œæ—¶é—´
                                    health_check_params = {"max_tokens": 100}
                                    
                                    # å…ˆå°è¯•ä¸»è¦æ ¼å¼
                                    try:
                                        curl_result = curl_infra.get_response(primary_messages, [], source_model_name, timeout=timeout, additional_params=health_check_params)
                                    except Exception as primary_error:
                                        # å¦‚æœæ˜¯å¤šæ¨¡æ€ä¸”æ ¼å¼é”™è¯¯ï¼Œå°è¯•å¤‡ç”¨æ ¼å¼
                                        if is_multimodal and "invalid type" in str(primary_error).lower():
                                            curl_result = curl_infra.get_response(fallback_messages, [], source_model_name, timeout=timeout, additional_params=health_check_params)
                                        else:
                                            raise primary_error
                                            
                                    end_time = datetime.now()
                                    if curl_result and "execution_time" in curl_result:
                                        execution_time = curl_result["execution_time"]
                                        data_structure[f"{source_name}|{model_name}"] = execution_time
                                        success_count += 1
                                        logger.debug(f"âœ… {source_name}|{model_name} - {execution_time:.2f}s")
                                    else:
                                        # å¦‚æœæ²¡æœ‰è¿”å›ç»“æœæˆ–ç¼ºå°‘execution_timeï¼Œå¯èƒ½æ˜¯éšæ€§è¶…æ—¶æˆ–APIå“åº”ä¸å®Œæ•´
                                        execution_time = (end_time - start_time).total_seconds()
                                        data_structure[f"{source_name}|{model_name}"] = None
                                        error_count += 1
                                        
                                        # è®°å½•ä¸ºè¶…æ—¶WARNINGçº§åˆ«
                                        logger.warning(f"â° æ— å“åº”: {source_name}|{model_name} ({execution_time:.2f}s)", 
                                                      extra={
                                                          'source': source_name,
                                                          'model': model_name,
                                                          'api_type': 'CURL',
                                                          'timeout': timeout,
                                                          'execution_time': execution_time,
                                                          'error_type': 'NoResponse'
                                                      })
                                    request_id = str(uuid.uuid4())
                                    
                                    # è®°å½•APIå¯†é’¥ä½¿ç”¨æƒ…å†µï¼ˆæˆåŠŸï¼‰
                                    api_key_client.notice_api_key_usage(
                                        api_key=api_key,
                                        model_name=source_model_name,
                                        source_name=source_name,
                                        create_time=start_time,
                                        finish_time=end_time,
                                        execution_time=execution_time,
                                        status=True,
                                        prompt_tokens=curl_result.get("prompt_tokens"),
                                        completion_tokens=curl_result.get("completion_tokens"),
                                        request_id=request_id,
                                        remark="æµ‹è¯•-å¥åº·ç›‘æµ‹"
                                    )
                                except Exception as e:
                                    end_time = datetime.now()
                                    execution_time = (end_time - start_time).total_seconds()
                                    request_id = str(uuid.uuid4())
                                    error_count += 1
                                    
                                    # è®°å½•APIå¯†é’¥ä½¿ç”¨æƒ…å†µï¼ˆå¤±è´¥ï¼‰
                                    api_key_client.notice_api_key_usage(
                                        api_key=api_key,
                                        model_name=source_model_name,
                                        source_name=source_name,
                                        create_time=start_time,
                                        finish_time=end_time,
                                        execution_time=execution_time,
                                        status=False,
                                        request_id=request_id,
                                        remark="æµ‹è¯•-å¥åº·ç›‘æµ‹"
                                    )
                                    
                                    # æ ¹æ®é”™è¯¯ç±»å‹ç¡®å®šæ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯
                                    log_level, should_log, log_message = _get_error_level_and_message(
                                        str(e), type(e).__name__, source_name, model_name)
                                    
                                    if should_log:
                                        extra_info = {
                                            'source': source_name,
                                            'model': model_name,
                                            'api_type': 'CURL',
                                            'timeout': timeout,
                                            'error_type': type(e).__name__,
                                            'execution_time': execution_time
                                        }
                                        
                                        if log_level == 'ERROR':
                                            logger.error(log_message, extra=extra_info)
                                        elif log_level == 'WARNING':
                                            logger.warning(log_message, extra=extra_info)
                                        else:  # DEBUG
                                            logger.debug(log_message, extra=extra_info)
                                    data_structure[f"{source_name}|{model_name}"] = None
                    except Exception as e:
                        logger.error(f"ğŸ”§ å¤„ç†å¤±è´¥: {source_name}|{model_name} - {create_error_summary(str(e), type(e).__name__, source_name, model_name)}")
                        data_structure[f"{source_name}|{model_name}"] = None
                        error_count += 1
            
            # ç”Ÿæˆè¯¦ç»†çš„æ±‡æ€»æŠ¥å‘Š
            _generate_health_check_summary_report(total_tests, success_count, error_count, data_structure)
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å¥åº·æ£€æŸ¥æ€»ä½“é”™è¯¯: {create_error_summary(str(e), type(e).__name__, None, None)}")
            
        return data_structure

def _generate_health_check_summary_report(total_tests: int, success_count: int, error_count: int, data_structure: dict):
    """ç”Ÿæˆå¥åº·æ£€æŸ¥çš„è¯¦ç»†æ±‡æ€»æŠ¥å‘Š"""
    success_rate = (success_count / total_tests * 100) if total_tests > 0 else 0
    
    logger.info("ğŸ¥ ==================== å¥åº·æ£€æŸ¥æ±‡æ€»æŠ¥å‘Š ====================")
    logger.info(f"ğŸ¥ æ€»æµ‹è¯•æ•°: {total_tests}")
    logger.info(f"ğŸ¥ æˆåŠŸæ•°: {success_count}")
    logger.info(f"ğŸ¥ å¤±è´¥æ•°: {error_count}")
    logger.info(f"ğŸ¥ æˆåŠŸç‡: {success_rate:.1f}%")
    
    # æŒ‰æºç»Ÿè®¡
    source_stats = defaultdict(lambda: {'total': 0, 'success': 0, 'failed': 0, 'avg_time': 0, 'models': set()})
    
    for key, value in data_structure.items():
        if '|' in key:
            source_name, model_name = key.split('|', 1)
            source_stats[source_name]['total'] += 1
            source_stats[source_name]['models'].add(model_name)
            
            if value is not None:
                source_stats[source_name]['success'] += 1
                source_stats[source_name]['avg_time'] += value
            else:
                source_stats[source_name]['failed'] += 1
    
    # è®¡ç®—å¹³å‡æ—¶é—´
    for stats in source_stats.values():
        if stats['success'] > 0:
            stats['avg_time'] = stats['avg_time'] / stats['success']
    
    # æŒ‰æˆåŠŸç‡æ’åºæ˜¾ç¤ºæºç»Ÿè®¡
    sorted_sources = sorted(source_stats.items(), 
                          key=lambda x: (x[1]['success'] / x[1]['total'] if x[1]['total'] > 0 else 0), 
                          reverse=True)
    
    logger.info("ğŸ¥ å„æºè¯¦ç»†ç»Ÿè®¡:")
    for source_name, stats in sorted_sources:
        source_success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
        logger.info(f"ğŸ¥   [{source_name}]: {stats['success']}/{stats['total']} æˆåŠŸ ({source_success_rate:.1f}%)")
        if stats['success'] > 0:
            logger.info(f"ğŸ¥     - å¹³å‡å“åº”æ—¶é—´: {stats['avg_time']:.2f}s")
        logger.info(f"ğŸ¥     - æ”¯æŒæ¨¡å‹æ•°: {len(stats['models'])}")
        
        # æ˜¾ç¤ºå¤±è´¥æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
        failed_models = []
        for model_name in stats['models']:
            key = f"{source_name}|{model_name}"
            if data_structure.get(key) is None:
                failed_models.append(model_name)
        
        if failed_models:
            models_display = ', '.join(failed_models[:5])
            if len(failed_models) > 5:
                models_display += f"... (å…±{len(failed_models)}ä¸ª)"
            logger.info(f"ğŸ¥     - å¤±è´¥æ¨¡å‹: {models_display}")
    
    # æœ€å¿«å’Œæœ€æ…¢çš„æ¨¡å‹
    successful_models = [(k, v) for k, v in data_structure.items() if v is not None]
    if successful_models:
        fastest = min(successful_models, key=lambda x: x[1])
        slowest = max(successful_models, key=lambda x: x[1])
        logger.info(f"ğŸ¥ æœ€å¿«å“åº”: {fastest[0]} ({fastest[1]:.2f}s)")
        logger.info(f"ğŸ¥ æœ€æ…¢å“åº”: {slowest[0]} ({slowest[1]:.2f}s)")
    
    logger.info("ğŸ¥ ===============================================================")

def update_health_data():
    """Run the health check and update the sliding window data"""
    logger.debug(f"[{datetime.now()}] å¼€å§‹å®šæ—¶å¥åº·æ£€æŸ¥...")
    try:
        new_data = CheckHealthy.run()
        
        # Update sliding window for each key
        for key, value in new_data.items():
            if key not in health_data:
                health_data[key] = deque(maxlen=MAX_WINDOW_SIZE)
            
            health_data[key].append(value)
        
        logger.debug(f"[{datetime.now()}] å¥åº·æ£€æŸ¥å®Œæˆï¼Œæ›´æ–°äº† {len(new_data)} ä¸ªæŒ‡æ ‡")
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥æ•°æ®æ›´æ–°å¤±è´¥: {str(e)}")

# Initialize the scheduler
scheduler = BackgroundScheduler()
scheduler.add_job(
    update_health_data,
    trigger=IntervalTrigger(minutes=CHECK_TIMER_SPAN),
    id="health_check_job",
    name=f"Run API health check every {CHECK_TIMER_SPAN} minutes",
    replace_existing=True,
    max_instances=1,  # ç¡®ä¿åªæœ‰ä¸€ä¸ªå®ä¾‹åœ¨è¿è¡Œ
    misfire_grace_time=300  # å¦‚æœé”™è¿‡äº†æ‰§è¡Œæ—¶é—´ï¼Œ5åˆ†é’Ÿå†…ä»ç„¶ä¼šæ‰§è¡Œ
)

@app.on_event("startup")
async def startup_event():
    """Run initial health check and start the scheduler"""
    logger.info("APIå¥åº·æ£€æŸ¥æœåŠ¡æ­£åœ¨å¯åŠ¨...")
    
    # åˆå§‹åŒ–ç©ºæ•°æ®ï¼Œç¡®ä¿APIç«‹å³å¯ç”¨
    all_models = model_list_normal + model_list_thinking + model_list_mm_normal + model_list_mm_thinking
    for model_name in all_models:
        for source_name in source_mapping:
            key = f"{source_name}|{model_name}"
            if key not in health_data:
                health_data[key] = deque(maxlen=MAX_WINDOW_SIZE)
                
    # ä¸ºå±è”½æ¨¡å‹åˆå§‹åŒ–ç©ºçš„å¥åº·æ•°æ®ç»“æ„ï¼Œç¡®ä¿LoadBalancingèƒ½æ­£å¸¸è¯†åˆ«å®ƒä»¬ä¸ºæ— å¥åº·æ•°æ®çŠ¶æ€
    blacklisted_models = [model for model in all_models if is_model_health_check_blacklisted(model)]
    if blacklisted_models:
        logger.info(f"ğŸš« ä¸º {len(blacklisted_models)} ä¸ªå±è”½æ¨¡å‹åˆå§‹åŒ–ç©ºå¥åº·æ•°æ®ç»“æ„ï¼ˆæ”¯æŒå±‚çº§å±è”½ï¼‰")
    
    # Start the scheduler
    scheduler.start()
    logger.info("å¥åº·æ£€æŸ¥è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    # åœ¨åå°è¿è¡Œåˆå§‹å¥åº·æ£€æŸ¥ï¼Œä¸é˜»å¡APIå¯åŠ¨
    logger.info("æ­£åœ¨åå°å¯åŠ¨åˆå§‹å¥åº·æ£€æŸ¥...")

@app.on_event("shutdown")
async def shutdown_event():
    """Shutdown the scheduler when the app stops and save health data to a local file"""
    logger.info("æœåŠ¡å…³é—­ä¸­ï¼Œä¿å­˜å¥åº·æ£€æŸ¥æ•°æ®...")
    
    # Convert deque objects to lists for JSON serialization
    result = {k: list(v) for k, v in health_data.items()}
    
    # Create data object with timestamp
    data_to_save = {
        "timestamp": datetime.now().isoformat(),
        "check_timer_span": CHECK_TIMER_SPAN,
        "data": result
    }
    
    # Create directory if it doesn't exist
    os.makedirs("data", exist_ok=True)
    
    # Save to file with timestamp in filename
    filename = f"data/health_check_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, "w") as f:
        json.dump(data_to_save, f, indent=2)
    
    logger.info(f"å¥åº·æ£€æŸ¥æ•°æ®å·²ä¿å­˜åˆ° {filename}")
    
    # Shutdown the scheduler
    scheduler.shutdown()
    logger.info("å¥åº·æ£€æŸ¥è°ƒåº¦å™¨å·²å…³é—­")

@app.get("/check_healthy")
async def get_health_data():
    """Return the sliding window data for all API checks"""
    logger.debug("æ¥æ”¶åˆ°å¥åº·æ£€æŸ¥æ•°æ®è¯·æ±‚")
    # Convert deque objects to lists for JSON serialization
    result = {k: list(v) for k, v in health_data.items()}
    return {
        "timestamp": datetime.now().isoformat(),
        "check_timer_span": CHECK_TIMER_SPAN,
        "data": result
    }

# Add a manual trigger endpoint for testing
@app.post("/trigger_health_check")
async def trigger_health_check(background_tasks: BackgroundTasks):
    """Manually trigger a health check (runs in background)"""
    logger.info("æ”¶åˆ°æ‰‹åŠ¨è§¦å‘å¥åº·æ£€æŸ¥è¯·æ±‚")
    background_tasks.add_task(update_health_data)
    return {"status": "å¥åº·æ£€æŸ¥å·²åœ¨åå°è§¦å‘"}

@app.get("/docker-health")
async def docker_health_check():
    """ä¸“é—¨ä¸ºDockerå¥åº·æ£€æŸ¥è®¾è®¡çš„ç«¯ç‚¹ï¼ŒéªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"""
    try:
        # æ£€æŸ¥API Key ManageræœåŠ¡å¯ç”¨æ€§
        api_key_client = APIKeyManagerClient(API_KEY_MANAGER_URL)
        
        # å°è¯•ç®€å•è¿æ¥ï¼Œå¦‚æœèƒ½è·å–åˆ°ä¸€ä¸ªAPI keyå°±è®¤ä¸ºæœåŠ¡è¿è¡Œæ­£å¸¸
        test_key = api_key_client.get_api_key("openai")
        
        # å³ä½¿æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„keyï¼Œåªè¦æ²¡æœ‰æŠ›å‡ºå¼‚å¸¸å°±è®¤ä¸ºæœåŠ¡å¯ç”¨
        logger.debug("Dockerå¥åº·æ£€æŸ¥é€šè¿‡")
        return {"status": "healthy", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"Dockerå¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # Only use this for local development
    # In production, use the proper Docker setup
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="error")